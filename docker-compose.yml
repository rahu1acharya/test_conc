services:
  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      ZOOKEEPER_SYNC_LIMIT: 2

  broker:
    image: confluentinc/cp-kafka:latest
    hostname: broker
    container_name: broker2
    ports:
      - 9092:9092
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT,CONTROLLER:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_NODE_ID: 1
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@broker:29093
      KAFKA_LISTENERS: PLAINTEXT://broker:29092,CONTROLLER://broker:29093,PLAINTEXT_HOST://0.0.0.0:9092
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
 
      KAFKA_LOG_DIRS: /tmp/kraft-combined-logs
      CLUSTER_ID: MkU3OEVBNTcwNTJENDM2Qk

  kafka-connect:
    image: confluentinc/cp-kafka-connect:latest
    hostname: kafka-connect
    container_name: kconnect2
    ports:
      - 8083:8083
    environment:
      CONNECT_BOOTSTRAP_SERVERS: broker:29092
      CONNECT_REST_ADVERTISED_HOST_NAME: kafka-connect
      CONNECT_GROUP_ID: "connect-cluster"
      CONNECT_CONFIG_STORAGE_TOPIC: "connect-configs"
      CONNECT_OFFSET_STORAGE_TOPIC: "connect-offsets"
      CONNECT_STATUS_STORAGE_TOPIC: "connect-status"
      CONNECT_KEY_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_VALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_INTERNAL_KEY_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_INTERNAL_VALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_PLUGIN_PATH: '/usr/share/java,/etc/kafka-connect/jars'
      CONNECT_REST_PORT: 8083
    volumes:
      - ./jars:/etc/kafka-connect/jars
    depends_on:
      - broker

  control-center:
      image: confluentinc/cp-enterprise-control-center:latest
      ports:
        - 9021:9021
      depends_on:
        - zookeeper
        - broker
        - kafka-connect
      environment:
        CONTROL_CENTER_BOOTSTRAP_SERVERS: broker:29092
        CONTROL_CENTER_ZOOKEEPER_CONNECT: zookeeper:2181
        CONTROL_CENTER_CONNECT_CLUSTER: kafka-connect:8083
        CONTROL_CENTER_INTERNAL_TOPICS_PARTITIONS: 1
        CONTROL_CENTER_MONITORING_INTERCEPTOR_TOPIC_PARTITIONS: 1
        CONTROL_CENTER_GROUP_TOPIC_PARTITIONS: 1
        CONTROL_CENTER_INTERNAL_TOPIC_REPLICATION: 1
        CONTROL_CENTER_COMMAND_TOPIC_REPLICATION: 1
        CONTROL_CENTER_CONTROL_TOPIC_REPLICATION: 1
        CONTROL_CENTER_SAFETY_VALVE_TOPIC_REPLICATION: 1
        CONTROL_CENTER_ZOOKEEPER_TIMEOUT_MS: 10000
        CONTROL_CENTER_ZOOKEEPER_CONNECT_TIMEOUT_MS: 10000
        CONTROL_CENTER_REPLICATION_FACTOR: 1

  aws-glue:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: aws-glue2
    volumes:
      - ./src/glue:/home/glue_user/workspace/
    stdin_open: true
    tty: true
    depends_on:
      - broker

  vault:
    build:
      context: .
      dockerfile: vaultdock
    container_name: vault2
    ports:
      - "8200:8200"
    environment:
      VAULT_ADDR: http://0.0.0.0:8200
      VAULT_DEV_ROOT_TOKEN_ID: rahul
    volumes:
      - vault-data:/vault/data
    # networks:
    #   - vault-concourse_concourse-net

  concourse-db:
    image: postgres
    environment:
      POSTGRES_DB: concourse
      POSTGRES_PASSWORD: concourse_pass
      POSTGRES_USER: concourse_user
      PGDATA: /database
    ports:
      - "5432:5432" 
    # networks:
    #   - vault-concourse_concourse-net


  concourse:
    image: concourse/concourse
    command: quickstart
    privileged: true
    depends_on: [concourse-db]
    ports: ["8080:8080"]
    environment:
      CONCOURSE_POSTGRES_HOST: concourse-db
      CONCOURSE_POSTGRES_USER: concourse_user
      CONCOURSE_POSTGRES_PASSWORD: concourse_pass
      CONCOURSE_POSTGRES_DATABASE: concourse
      CONCOURSE_EXTERNAL_URL: http://localhost:8080
      CONCOURSE_ADD_LOCAL_USER: test:test
      CONCOURSE_MAIN_TEAM_LOCAL_USER: test
      # instead of relying on the default "detect"
      CONCOURSE_WORKER_BAGGAGECLAIM_DRIVER: overlay
      CONCOURSE_CLIENT_SECRET: Y29uY291cnNlLXdlYgo=
      CONCOURSE_TSA_CLIENT_SECRET: Y29uY291cnNlLXdvcmtlcgo=
      CONCOURSE_X_FRAME_OPTIONS: allow
      CONCOURSE_CONTENT_SECURITY_POLICY: "*"
      CONCOURSE_CLUSTER_NAME: tutorial
      CONCOURSE_WORKER_CONTAINERD_DNS_SERVER: "8.8.8.8"
      # For ARM-based machine, change the Concourse runtime to "houdini"
      CONCOURSE_WORKER_RUNTIME: "containerd"
    # networks:
    #   - vault-concourse_concourse-net

# networks:
#   vault-concourse_concourse-net:
#     external: 'true'

volumes:
  postgres-data:
  vault-data: